# RCNN

step1：训练分类网络（Alexnet)

step2：对模型做fine-tuning

​				类别1000改为2（总共21类包含一个背景）

​				去掉FC层（因为FC层参数不同不可用 相当于只保留了主干卷积层）)

```
fine tuning的过程其实就是用训练好的参数（可以从已训练好的模型（如VGG、Resnet、zf、Alexne）中获得）初始化自己的网络，然后用自己的数据接着训练，参数的调整方法与from scratch训练过程一样（梯度下降）。对于初始化过程，我们可以称自己的网络为目标网络，训练好的模型对应网络为源网络，要求目标网络待初始化的层要与源网络的层相同（层的名字、类型以及层的设置参数等等均相同）。
（详细见 https://blog.csdn.net/clearch/article/details/80231127）
（https://blog.csdn.net/helei001/article/details/53159690 怎么使用TensorFlow调用预训练好的VGG网络）
```

step3：特征提取

​				1.提取候选框（选择性搜索selective search，SS）

```
**选择性搜索**
1.生成区域集R（进行区域分割）
2.计算区域R里每个相邻区域的相似度S={s1,s2...}
3.找出相似度最高的两个区域，并将其合并成为新集，添加进R
4.从S中移除和上一步相关的子集
5.重新计算新集和所有子集的相似度
6.跳至3直至S为空
```

​				2.对每个区域，修正区域为CNN的输入，利用网络对候选框进行提取特征

step4：训练SVM分类器，每个类别一个SVM（20+1个）

step5：回归器精修候选框位置：利用线性回归模型判定框的准确度



**RCNN缺点**

```
1.候选框选择算法耗时严重（难以实时）
2.重叠区域特征重复计算（先算特征再进行选择性搜索，导致某部分会重复计算可以先用CNN）
3.分步骤进行过程繁琐（采用了传统检测的方法，先CNN->SVM->回归模型 相对于端->端的显得很繁琐）
```

